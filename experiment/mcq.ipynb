{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\",temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "  \"1\": {\n",
    "    \"mcq\":\"multiple choice question\",\n",
    "    \"options\":{\n",
    "      \"a\":\"choice here\",\n",
    "      \"b\":\"choice here\",\n",
    "      \"c\":\"choice here\",\n",
    "      \"d\":\"choice here\",\n",
    "    },\n",
    "    \"correct\":\"correct answer\",\n",
    "  },\n",
    "    \"2\": {\n",
    "    \"mcq\":\"multiple choice question\",\n",
    "    \"options\":{\n",
    "      \"a\":\"choice here\",\n",
    "      \"b\":\"choice here\",\n",
    "      \"c\":\"choice here\",\n",
    "      \"d\":\"choice here\",\n",
    "    },\n",
    "    \"correct\":\"correct answer\",\n",
    "  },\n",
    "    \"3\": {\n",
    "    \"mcq\":\"multiple choice question\",\n",
    "    \"options\":{\n",
    "      \"a\":\"choice here\",\n",
    "      \"b\":\"choice here\",\n",
    "      \"c\":\"choice here\",\n",
    "      \"d\":\"choice here\",\n",
    "    },\n",
    "    \"correct\":\"correct answer\",\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text={text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz od {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure the questions are not repeated and check all the questions to be comforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide.\\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "  input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "  template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Template2=\"\"\"\n",
    "You are an expert english grammarian and writer.Given a Multiple choice quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity\n",
    "if the quiz is not at per with the cognitive and analytical abilities od the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(input_variables=[\"subject\",\"quiz\"], template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain],\n",
    "                                        input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "                                        output_variables=[\"quiz\",\"review\"],\n",
    "                                        verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =r\"/Users/yingyinghao/mcqgen/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "  TEXT =file.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method read of _io.TextIOWrapper object at 0x17b0c9450>\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 5\n",
    "SUBJECT =\"machine learning\"\n",
    "TONE='simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text=<built-in method read of _io.TextIOWrapper object at 0x17b0c9450>\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz od 5 multiple choice questions for machine learning students in simple tone.\n",
      "Make sure the questions are not repeated and check all the questions to be comforming the text as well.\n",
      "Make sure to format your response like RESPONSE_JSON below and use it as a guide.Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text=<built-in method read of _io.TextIOWrapper object at 0x17b0c9450>\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz od 5 multiple choice questions for machine learning students in simple tone.\n",
      "Make sure the questions are not repeated and check all the questions to be comforming the text as well.\n",
      "Make sure to format your response like RESPONSE_JSON below and use it as a guide.Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#how to setup Token Usage Tracking in Langchain\n",
    "with get_openai_callback() as cb:\n",
    "  response=generate_evaluate_chain(\n",
    "    {\n",
    "      \"text\": TEXT,\n",
    "      \"number\": NUMBER,\n",
    "      \"subject\":SUBJECT,\n",
    "      \"tone\":TONE,\n",
    "      \"response_json\":json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1326\n",
      "Prompt Tokens: 538\n",
      "Completion Tokens: 788\n",
      "Total cost: 0.002383\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "print(f\"Total cost: {cb.total_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "        mcq = value[\"mcq\"]\n",
    "        options = \" | \".join(\n",
    "            [\n",
    "                f\"{option}:{option_value}\"\n",
    "                for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "        correct = value[\"correct\"]\n",
    "        quiz_table_data.append({\"MCQ\":  mcq, \"Choices\": options, \"Correct\":correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
